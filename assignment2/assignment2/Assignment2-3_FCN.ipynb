{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment #2 Part 3: Semantic Segmentation using FCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Data Science & Artificial Intelligence Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. June 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you will implement Fully Convolutional Networks(FCNs)[3] to perform semantic segmentation on Kitti-road dataset. <br>\n",
    "\n",
    "Most of coes are completed for your convenience except FCN model.\n",
    "\n",
    "There is **1 section**, and you need to follow the instructions to complete the skeleton codes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameters and load datasets\n",
    "The datasets in the *Utils* directory will be loaded automatically. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from Utils.batch import gen_batch_function\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from Utils.fcn import FcnModel\n",
    "from Utils.data_utils import maybe_download_and_extract, load_kitti_road, save_test_samples\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2'\n",
    "\n",
    "dataset = './data'\n",
    "test_output_dir = './test_run'\n",
    "model = \"models/model.ckpt\"\n",
    "epochs = 20\n",
    "batch = 64\n",
    "lr = 1e-2\n",
    "\n",
    "image_shape = (576, 160)\n",
    "num_classes = 2\n",
    "\n",
    "# Create function to get batches\n",
    "get_batches_fn = load_kitti_road(image_shape)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kitti Road Dataset Sample\n",
    "### data <img src=\"Utils/um_000000.png\" alt=\"drawing\" width=\"400\"/>\n",
    "### label <img src=\"Utils/um_lane_000000.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Pretrained VGG-16\n",
    "The pretrained VGG-16 will be downloaded automatically if it is not located in the *Utils* directory. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maybe_download_and_extract('http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz')\n",
    "\n",
    "'''Function for load VGG-16 to tf-session'''\n",
    "def load_vgg_ckpt(sess):\n",
    "    ckpt = 'Utils/vgg_16.ckpt'\n",
    "    variables = slim.get_variables(scope='vgg_16', suffix=\"weights\") + slim.get_variables(scope='vgg_16', suffix=\"biases\")\n",
    "    init_assign_op, init_feed_dict = slim.assign_from_checkpoint(ckpt, variables)\n",
    "    sess.run(init_assign_op, init_feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"2\"></a> Training FCN model with Pretrained VGG-16\n",
    "\n",
    "In this section, you will implement FCN model with pretrained VGG-16. <br>\n",
    "\n",
    "<img src=\"Utils/FCN.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "<b>Complete the code in 'Utils/fcn.py' with reference to above image. <br>\n",
    "Then, run below cells. (If you don't fill the 'Utils/fcn.py', error will be occured in below cells.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    x_placeholder = tf.placeholder(tf.float32, [None, image_shape[0], image_shape[1], 3])\n",
    "    y_placeholder = tf.placeholder(tf.float32, [None, image_shape[0], image_shape[1], num_classes])\n",
    "    lr_placeholder = tf.placeholder(tf.float32)\n",
    "    is_train_placeholder = tf.placeholder(tf.bool)\n",
    "    fcn_model = FcnModel(x_placeholder, y_placeholder, is_train_placeholder, num_classes)\n",
    "\n",
    "    global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "    train_opt = tf.train.AdamOptimizer(lr_placeholder).minimize(fcn_model.loss, global_step)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        load_vgg_ckpt(sess)\n",
    "        saver = tf.train.Saver()\n",
    "        writer = tf.summary.FileWriter('graphs/train', sess.graph)\n",
    "\n",
    "        best_loss = np.inf\n",
    "        for epoch in range(int(epochs)):\n",
    "            total_loss_value = 0\n",
    "            for images, labels in get_batches_fn(int(batch)):\n",
    "                feed = {x_placeholder: images,\n",
    "                        y_placeholder: labels,\n",
    "                        lr_placeholder: lr,\n",
    "                        is_train_placeholder : True }\n",
    "            \n",
    "                _, loss_value, summary_value = sess.run([train_opt, fcn_model.loss, fcn_model.summary],\n",
    "                                                        feed_dict = feed)\n",
    "                total_loss_value += loss_value\n",
    "                \n",
    "                writer.add_summary(summary_value, sess.run(global_step))\n",
    "            print(\"epoch: {}/{}, training loss: {:.2f}\".format(epoch+1, int(epochs), total_loss_value))\n",
    "            if total_loss_value < best_loss:\n",
    "                saver.save(sess, \"models/model.ckpt\")\n",
    "                print(\"    best model update!!!\")\n",
    "         \n",
    "        logits = tf.reshape(fcn_model.inference_op, (-1, num_classes))\n",
    "        save_test_samples(test_output_dir, sess, image_shape, logits, is_train_placeholder, x_placeholder)\n",
    " \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Output Image\n",
    "\n",
    "Visualize one of the output images. You can see all of them in test_output_dir. (Default directory is './test_run/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_dir = os.path.join(test_output_dir, 'umm_000011.png')\n",
    "im = Image.open(plt_dir)\n",
    "plt.imshow(im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hyundai3.6.5] *",
   "language": "python",
   "name": "conda-env-hyundai3.6.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
